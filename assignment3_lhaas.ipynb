{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PORTAL</th>\n",
       "      <th>Date</th>\n",
       "      <th>time_from</th>\n",
       "      <th>time_to</th>\n",
       "      <th>Interval_5</th>\n",
       "      <th>SPEED_MS_AVG</th>\n",
       "      <th>flow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E4S 56,780</td>\n",
       "      <td>20210101</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00:05:00</td>\n",
       "      <td>0</td>\n",
       "      <td>18.56</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E4S 56,780</td>\n",
       "      <td>20210101</td>\n",
       "      <td>00:05:00</td>\n",
       "      <td>00:10:00</td>\n",
       "      <td>1</td>\n",
       "      <td>20.39</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E4S 56,780</td>\n",
       "      <td>20210101</td>\n",
       "      <td>00:10:00</td>\n",
       "      <td>00:15:00</td>\n",
       "      <td>2</td>\n",
       "      <td>19.27</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E4S 56,780</td>\n",
       "      <td>20210101</td>\n",
       "      <td>00:15:00</td>\n",
       "      <td>00:20:00</td>\n",
       "      <td>3</td>\n",
       "      <td>19.52</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E4S 56,780</td>\n",
       "      <td>20210101</td>\n",
       "      <td>00:20:00</td>\n",
       "      <td>00:25:00</td>\n",
       "      <td>4</td>\n",
       "      <td>20.52</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104838</th>\n",
       "      <td>E4S 56,780</td>\n",
       "      <td>20211231</td>\n",
       "      <td>23:35:00</td>\n",
       "      <td>23:40:00</td>\n",
       "      <td>283</td>\n",
       "      <td>19.58</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104839</th>\n",
       "      <td>E4S 56,780</td>\n",
       "      <td>20211231</td>\n",
       "      <td>23:40:00</td>\n",
       "      <td>23:45:00</td>\n",
       "      <td>284</td>\n",
       "      <td>19.47</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104840</th>\n",
       "      <td>E4S 56,780</td>\n",
       "      <td>20211231</td>\n",
       "      <td>23:45:00</td>\n",
       "      <td>23:50:00</td>\n",
       "      <td>285</td>\n",
       "      <td>19.77</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104841</th>\n",
       "      <td>E4S 56,780</td>\n",
       "      <td>20211231</td>\n",
       "      <td>23:50:00</td>\n",
       "      <td>23:55:00</td>\n",
       "      <td>286</td>\n",
       "      <td>18.79</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104842</th>\n",
       "      <td>E4S 56,780</td>\n",
       "      <td>20211231</td>\n",
       "      <td>23:55:00</td>\n",
       "      <td>24:00:00</td>\n",
       "      <td>287</td>\n",
       "      <td>18.75</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104843 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            PORTAL      Date time_from   time_to  Interval_5  SPEED_MS_AVG  \\\n",
       "0       E4S 56,780  20210101  00:00:00  00:05:00           0         18.56   \n",
       "1       E4S 56,780  20210101  00:05:00  00:10:00           1         20.39   \n",
       "2       E4S 56,780  20210101  00:10:00  00:15:00           2         19.27   \n",
       "3       E4S 56,780  20210101  00:15:00  00:20:00           3         19.52   \n",
       "4       E4S 56,780  20210101  00:20:00  00:25:00           4         20.52   \n",
       "...            ...       ...       ...       ...         ...           ...   \n",
       "104838  E4S 56,780  20211231  23:35:00  23:40:00         283         19.58   \n",
       "104839  E4S 56,780  20211231  23:40:00  23:45:00         284         19.47   \n",
       "104840  E4S 56,780  20211231  23:45:00  23:50:00         285         19.77   \n",
       "104841  E4S 56,780  20211231  23:50:00  23:55:00         286         18.79   \n",
       "104842  E4S 56,780  20211231  23:55:00  24:00:00         287         18.75   \n",
       "\n",
       "        flow  \n",
       "0         39  \n",
       "1         18  \n",
       "2         26  \n",
       "3         52  \n",
       "4         52  \n",
       "...      ...  \n",
       "104838   115  \n",
       "104839    87  \n",
       "104840   130  \n",
       "104841   129  \n",
       "104842   117  \n",
       "\n",
       "[104843 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"dataset_exercise_5_clustering_highway_traffic.csv\",sep=\";\")\n",
    "\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ww/hnj0z7l577b2_jzdg6515pfm0000gn/T/ipykernel_2960/2050002240.py:22: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  df_t = day_subsets_df.get_group(days[i])\n",
      "/var/folders/ww/hnj0z7l577b2_jzdg6515pfm0000gn/T/ipykernel_2960/2050002240.py:27: FutureWarning: When grouping with a length-1 list-like, you will need to pass a length-1 tuple to get_group in a future version of pandas. Pass `(name,)` instead of `name` to silence this warning.\n",
      "  df_t = day_subsets_df.get_group(days[i])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 39.  18.  26. ...  32.  39.  34.]\n",
      " [ 30.  32.  27. ...  44.  41.  39.]\n",
      " [ 36.  44.  52. ...  50.  45.  23.]\n",
      " ...\n",
      " [ 20.  34.  31. ...  38.  42.  36.]\n",
      " [ 36.  40.  25. ...  38.  56.  35.]\n",
      " [ 33.  32.  34. ... 130. 129. 117.]]\n"
     ]
    }
   ],
   "source": [
    "# Sort the DataFrame 'data_df' by columns \"Date\" and \"Interval_5\"\n",
    "data_df.sort_values([\"Date\", \"Interval_5\"])\n",
    "\n",
    "# Extract unique dates from the sorted DataFrame\n",
    "days = np.unique(data_df[['Date']].values.ravel())\n",
    "# Calculate the total number of unique days\n",
    "ndays = len(days)\n",
    "\n",
    "# Group the DataFrame 'data_df' by the \"Date\" column\n",
    "day_subsets_df = data_df.groupby([\"Date\"])\n",
    "\n",
    "# Define the total number of 5-minute intervals in a day\n",
    "nintvals = 288\n",
    "\n",
    "# Create a matrix 'vectorized_day_dataset' filled with NaN values\n",
    "vectorized_day_dataset = np.zeros((ndays, nintvals))\n",
    "vectorized_day_dataset.fill(np.nan)\n",
    "\n",
    "# Loop through each unique day\n",
    "for i in range(0, ndays):\n",
    "    # Get the DataFrame corresponding to the current day\n",
    "    df_t = day_subsets_df.get_group(days[i])\n",
    "\n",
    "    # Loop through each row in the current day's DataFrame\n",
    "    for j in range(len(df_t)):\n",
    "        # Get the current day's DataFrame\n",
    "        df_t = day_subsets_df.get_group(days[i])\n",
    "\n",
    "        # Extract the \"Interval_5\" and \"flow\" values and populate 'vectorized_day_dataset'\n",
    "        vectorized_day_dataset[i, df_t.iloc[j][\"Interval_5\"]] = df_t.iloc[j][\"flow\"]\n",
    "\n",
    "# Print the resulting 'vectorized_day_dataset'\n",
    "print(vectorized_day_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of days with missing value 28\n"
     ]
    }
   ],
   "source": [
    "nans_per_day = np.sum(np.isnan(vectorized_day_dataset),1)\n",
    "print('number of days with missing value',np.size(np.where(nans_per_day > 0),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 10\n",
    "clusters = None\n",
    "#print(np.where(nans_per_day > 0)[0])\n",
    "vectorized_day_dataset_no_nans = vectorized_day_dataset[np.where(nans_per_day == 0)[0],:]\n",
    "days_not_nans = days[np.where(nans_per_day == 0)[0]]\n",
    "\n",
    "X_train, X_val = train_test_split(vectorized_day_dataset_no_nans, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of days with missing value 28\n"
     ]
    }
   ],
   "source": [
    "nans_per_day = np.sum(np.isnan(vectorized_day_dataset),1)\n",
    "print('number of days with missing value',np.size(np.where(nans_per_day > 0),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algo</th>\n",
       "      <th>params</th>\n",
       "      <th>sil</th>\n",
       "      <th>ch</th>\n",
       "      <th>db</th>\n",
       "      <th>n_clusters</th>\n",
       "      <th>noise</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE_filled</th>\n",
       "      <th>sil_filled</th>\n",
       "      <th>db_filled</th>\n",
       "      <th>rank_ext</th>\n",
       "      <th>rank_sil</th>\n",
       "      <th>rank_db</th>\n",
       "      <th>rank_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>agglo</td>\n",
       "      <td>k=7,link=average</td>\n",
       "      <td>0.279675</td>\n",
       "      <td>54.003427</td>\n",
       "      <td>0.845864</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.667871</td>\n",
       "      <td>43.153036</td>\n",
       "      <td>28.667871</td>\n",
       "      <td>0.279675</td>\n",
       "      <td>0.845864</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agglo</td>\n",
       "      <td>k=4,link=complete</td>\n",
       "      <td>0.279928</td>\n",
       "      <td>92.209611</td>\n",
       "      <td>1.007734</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.709749</td>\n",
       "      <td>43.538289</td>\n",
       "      <td>28.709749</td>\n",
       "      <td>0.279928</td>\n",
       "      <td>1.007734</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>agglo</td>\n",
       "      <td>k=3,link=complete</td>\n",
       "      <td>0.318667</td>\n",
       "      <td>54.845992</td>\n",
       "      <td>0.721327</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.555019</td>\n",
       "      <td>49.292986</td>\n",
       "      <td>33.555019</td>\n",
       "      <td>0.318667</td>\n",
       "      <td>0.721327</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>agglo</td>\n",
       "      <td>k=10,link=average</td>\n",
       "      <td>0.241411</td>\n",
       "      <td>39.605748</td>\n",
       "      <td>0.802769</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.234210</td>\n",
       "      <td>42.384047</td>\n",
       "      <td>28.234210</td>\n",
       "      <td>0.241411</td>\n",
       "      <td>0.802769</td>\n",
       "      <td>33.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>agglo</td>\n",
       "      <td>k=7,link=complete</td>\n",
       "      <td>0.274291</td>\n",
       "      <td>54.475372</td>\n",
       "      <td>1.116768</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.759843</td>\n",
       "      <td>43.268379</td>\n",
       "      <td>28.759843</td>\n",
       "      <td>0.274291</td>\n",
       "      <td>1.116768</td>\n",
       "      <td>44.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>agglo</td>\n",
       "      <td>k=3,link=average</td>\n",
       "      <td>0.281186</td>\n",
       "      <td>4.878789</td>\n",
       "      <td>0.519491</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.941645</td>\n",
       "      <td>61.760881</td>\n",
       "      <td>42.941645</td>\n",
       "      <td>0.281186</td>\n",
       "      <td>0.519491</td>\n",
       "      <td>57.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>agglo</td>\n",
       "      <td>k=5,link=complete</td>\n",
       "      <td>0.283361</td>\n",
       "      <td>76.685367</td>\n",
       "      <td>1.234156</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.775626</td>\n",
       "      <td>43.528410</td>\n",
       "      <td>28.775626</td>\n",
       "      <td>0.283361</td>\n",
       "      <td>1.234156</td>\n",
       "      <td>46.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>agglo</td>\n",
       "      <td>k=8,link=complete</td>\n",
       "      <td>0.254478</td>\n",
       "      <td>48.866330</td>\n",
       "      <td>1.096967</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.498034</td>\n",
       "      <td>42.679963</td>\n",
       "      <td>28.498034</td>\n",
       "      <td>0.254478</td>\n",
       "      <td>1.096967</td>\n",
       "      <td>34.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>agglo</td>\n",
       "      <td>k=3,link=ward</td>\n",
       "      <td>0.285200</td>\n",
       "      <td>132.731090</td>\n",
       "      <td>1.264086</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.536967</td>\n",
       "      <td>50.406958</td>\n",
       "      <td>31.536967</td>\n",
       "      <td>0.285200</td>\n",
       "      <td>1.264086</td>\n",
       "      <td>49.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>agglo</td>\n",
       "      <td>k=6,link=complete</td>\n",
       "      <td>0.274044</td>\n",
       "      <td>63.667614</td>\n",
       "      <td>1.209533</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.765797</td>\n",
       "      <td>43.272943</td>\n",
       "      <td>28.765797</td>\n",
       "      <td>0.274044</td>\n",
       "      <td>1.209533</td>\n",
       "      <td>45.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>agglo</td>\n",
       "      <td>k=4,link=average</td>\n",
       "      <td>0.273253</td>\n",
       "      <td>40.405907</td>\n",
       "      <td>0.701576</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.447224</td>\n",
       "      <td>49.025839</td>\n",
       "      <td>33.447224</td>\n",
       "      <td>0.273253</td>\n",
       "      <td>0.701576</td>\n",
       "      <td>55.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gmm</td>\n",
       "      <td>k=6,cov=tied</td>\n",
       "      <td>0.231655</td>\n",
       "      <td>87.742051</td>\n",
       "      <td>1.402888</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.101404</td>\n",
       "      <td>39.447150</td>\n",
       "      <td>25.101404</td>\n",
       "      <td>0.231655</td>\n",
       "      <td>1.402888</td>\n",
       "      <td>12.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>kmeans</td>\n",
       "      <td>k=6</td>\n",
       "      <td>0.231655</td>\n",
       "      <td>87.742051</td>\n",
       "      <td>1.402888</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.101404</td>\n",
       "      <td>39.447150</td>\n",
       "      <td>25.101404</td>\n",
       "      <td>0.231655</td>\n",
       "      <td>1.402888</td>\n",
       "      <td>12.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gmm</td>\n",
       "      <td>k=6,cov=full</td>\n",
       "      <td>0.231655</td>\n",
       "      <td>87.742051</td>\n",
       "      <td>1.402888</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.101404</td>\n",
       "      <td>39.447150</td>\n",
       "      <td>25.101404</td>\n",
       "      <td>0.231655</td>\n",
       "      <td>1.402888</td>\n",
       "      <td>12.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>agglo</td>\n",
       "      <td>k=8,link=average</td>\n",
       "      <td>0.263235</td>\n",
       "      <td>47.109865</td>\n",
       "      <td>0.805722</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.668674</td>\n",
       "      <td>43.108245</td>\n",
       "      <td>28.668674</td>\n",
       "      <td>0.263235</td>\n",
       "      <td>0.805722</td>\n",
       "      <td>42.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>gmm</td>\n",
       "      <td>k=4,cov=diag</td>\n",
       "      <td>0.259746</td>\n",
       "      <td>110.011784</td>\n",
       "      <td>1.340073</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.573478</td>\n",
       "      <td>47.941999</td>\n",
       "      <td>28.573478</td>\n",
       "      <td>0.259746</td>\n",
       "      <td>1.340073</td>\n",
       "      <td>36.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>gmm</td>\n",
       "      <td>k=3,cov=spherical</td>\n",
       "      <td>0.269547</td>\n",
       "      <td>133.871720</td>\n",
       "      <td>1.337581</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.506786</td>\n",
       "      <td>49.997916</td>\n",
       "      <td>31.506786</td>\n",
       "      <td>0.269547</td>\n",
       "      <td>1.337581</td>\n",
       "      <td>47.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>agglo</td>\n",
       "      <td>k=8,link=ward</td>\n",
       "      <td>0.191241</td>\n",
       "      <td>70.977072</td>\n",
       "      <td>1.368608</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.770931</td>\n",
       "      <td>37.955415</td>\n",
       "      <td>23.770931</td>\n",
       "      <td>0.191241</td>\n",
       "      <td>1.368608</td>\n",
       "      <td>2.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>gmm</td>\n",
       "      <td>k=4,cov=spherical</td>\n",
       "      <td>0.264074</td>\n",
       "      <td>111.882781</td>\n",
       "      <td>1.350662</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.527476</td>\n",
       "      <td>47.939751</td>\n",
       "      <td>28.527476</td>\n",
       "      <td>0.264074</td>\n",
       "      <td>1.350662</td>\n",
       "      <td>35.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>gmm</td>\n",
       "      <td>k=6,cov=diag</td>\n",
       "      <td>0.229674</td>\n",
       "      <td>87.272820</td>\n",
       "      <td>1.405755</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.063370</td>\n",
       "      <td>39.412470</td>\n",
       "      <td>25.063370</td>\n",
       "      <td>0.229674</td>\n",
       "      <td>1.405755</td>\n",
       "      <td>11.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      algo             params       sil          ch        db  n_clusters  \\\n",
       "0    agglo   k=7,link=average  0.279675   54.003427  0.845864           7   \n",
       "1    agglo  k=4,link=complete  0.279928   92.209611  1.007734           4   \n",
       "2    agglo  k=3,link=complete  0.318667   54.845992  0.721327           3   \n",
       "3    agglo  k=10,link=average  0.241411   39.605748  0.802769          10   \n",
       "4    agglo  k=7,link=complete  0.274291   54.475372  1.116768           7   \n",
       "5    agglo   k=3,link=average  0.281186    4.878789  0.519491           3   \n",
       "6    agglo  k=5,link=complete  0.283361   76.685367  1.234156           5   \n",
       "7    agglo  k=8,link=complete  0.254478   48.866330  1.096967           8   \n",
       "8    agglo      k=3,link=ward  0.285200  132.731090  1.264086           3   \n",
       "9    agglo  k=6,link=complete  0.274044   63.667614  1.209533           6   \n",
       "10   agglo   k=4,link=average  0.273253   40.405907  0.701576           4   \n",
       "11     gmm       k=6,cov=tied  0.231655   87.742051  1.402888           6   \n",
       "12  kmeans                k=6  0.231655   87.742051  1.402888           6   \n",
       "13     gmm       k=6,cov=full  0.231655   87.742051  1.402888           6   \n",
       "14   agglo   k=8,link=average  0.263235   47.109865  0.805722           8   \n",
       "15     gmm       k=4,cov=diag  0.259746  110.011784  1.340073           4   \n",
       "16     gmm  k=3,cov=spherical  0.269547  133.871720  1.337581           3   \n",
       "17   agglo      k=8,link=ward  0.191241   70.977072  1.368608           8   \n",
       "18     gmm  k=4,cov=spherical  0.264074  111.882781  1.350662           4   \n",
       "19     gmm       k=6,cov=diag  0.229674   87.272820  1.405755           6   \n",
       "\n",
       "    noise        MAE       RMSE  MAE_filled  sil_filled  db_filled  rank_ext  \\\n",
       "0     0.0  28.667871  43.153036   28.667871    0.279675   0.845864      41.0   \n",
       "1     0.0  28.709749  43.538289   28.709749    0.279928   1.007734      43.0   \n",
       "2     0.0  33.555019  49.292986   33.555019    0.318667   0.721327      56.0   \n",
       "3     0.0  28.234210  42.384047   28.234210    0.241411   0.802769      33.0   \n",
       "4     0.0  28.759843  43.268379   28.759843    0.274291   1.116768      44.0   \n",
       "5     0.0  42.941645  61.760881   42.941645    0.281186   0.519491      57.0   \n",
       "6     0.0  28.775626  43.528410   28.775626    0.283361   1.234156      46.0   \n",
       "7     0.0  28.498034  42.679963   28.498034    0.254478   1.096967      34.0   \n",
       "8     0.0  31.536967  50.406958   31.536967    0.285200   1.264086      49.0   \n",
       "9     0.0  28.765797  43.272943   28.765797    0.274044   1.209533      45.0   \n",
       "10    0.0  33.447224  49.025839   33.447224    0.273253   0.701576      55.0   \n",
       "11    0.0  25.101404  39.447150   25.101404    0.231655   1.402888      12.0   \n",
       "12    0.0  25.101404  39.447150   25.101404    0.231655   1.402888      12.0   \n",
       "13    0.0  25.101404  39.447150   25.101404    0.231655   1.402888      12.0   \n",
       "14    0.0  28.668674  43.108245   28.668674    0.263235   0.805722      42.0   \n",
       "15    0.0  28.573478  47.941999   28.573478    0.259746   1.340073      36.0   \n",
       "16    0.0  31.506786  49.997916   31.506786    0.269547   1.337581      47.0   \n",
       "17    0.0  23.770931  37.955415   23.770931    0.191241   1.368608       2.0   \n",
       "18    0.0  28.527476  47.939751   28.527476    0.264074   1.350662      35.0   \n",
       "19    0.0  25.063370  39.412470   25.063370    0.229674   1.405755      11.0   \n",
       "\n",
       "    rank_sil  rank_db  rank_sum  \n",
       "0        6.0      8.0      55.0  \n",
       "1        5.0      9.0      57.0  \n",
       "2        1.0      4.0      61.0  \n",
       "3       23.0      6.0      62.0  \n",
       "4        7.0     11.0      62.0  \n",
       "5        4.0      1.0      62.0  \n",
       "6        3.0     14.0      63.0  \n",
       "7       21.0     10.0      65.0  \n",
       "8        2.0     15.0      66.0  \n",
       "9        8.0     13.0      66.0  \n",
       "10       9.0      3.0      67.0  \n",
       "11      28.0     28.0      68.0  \n",
       "12      28.0     28.0      68.0  \n",
       "13      28.0     28.0      68.0  \n",
       "14      19.0      7.0      68.0  \n",
       "15      20.0     17.0      73.0  \n",
       "16      10.0     16.0      73.0  \n",
       "17      48.0     23.0      73.0  \n",
       "18      18.0     21.0      74.0  \n",
       "19      32.0     31.0      74.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================\n",
    "# Advanced-track grid search\n",
    "# ============================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "\n",
    "X0 = vectorized_day_dataset  \n",
    "mask = ~np.any(np.isnan(X0), axis=1)\n",
    "X = X0[mask]\n",
    "\n",
    "# 1) Split train/validation\n",
    "X_train, X_val = train_test_split(X, test_size=0.2, random_state=42)\n",
    "\n",
    "def safe_internal_metrics(X_fit, labels):\n",
    "    labels = np.asarray(labels)\n",
    "    valid = labels != -1\n",
    "    uniq = np.unique(labels[valid])\n",
    "    if uniq.size < 2:\n",
    "        return dict(sil=np.nan, ch=np.nan, db=np.nan, n_clusters=uniq.size, frac_noise=np.mean(labels==-1))\n",
    "    try:\n",
    "        sil = silhouette_score(X_fit[valid], labels[valid])\n",
    "        ch  = calinski_harabasz_score(X_fit[valid], labels[valid])\n",
    "        db  = davies_bouldin_score(X_fit[valid], labels[valid])\n",
    "        return dict(sil=sil, ch=ch, db=db, n_clusters=uniq.size, frac_noise=np.mean(labels==-1))\n",
    "    except Exception:\n",
    "        return dict(sil=np.nan, ch=np.nan, db=np.nan, n_clusters=uniq.size, frac_noise=np.mean(labels==-1))\n",
    "\n",
    "def centroids_from_train(X_fit, labels):\n",
    "    cents = []\n",
    "    ids = []\n",
    "    for c in sorted([c for c in np.unique(labels) if c != -1]):\n",
    "        cents.append(X_fit[labels == c].mean(axis=0))\n",
    "        ids.append(c)\n",
    "    if not cents:\n",
    "        return np.empty((0, X_fit.shape[1])), np.array([])\n",
    "    return np.vstack(cents), np.array(ids)\n",
    "\n",
    "def assign_to_nearest_centroid(X_new, centroids):\n",
    "    if centroids.shape[0] == 0:\n",
    "        return np.full(X_new.shape[0], -1)\n",
    "    x2 = np.sum(X_new**2, axis=1, keepdims=True)\n",
    "    c2 = np.sum(centroids**2, axis=1, keepdims=True).T\n",
    "    cross = X_new @ centroids.T\n",
    "    d2 = x2 + c2 - 2*cross\n",
    "    return np.argmin(d2, axis=1)\n",
    "\n",
    "def external_errors(X_val, cents, val_assign):\n",
    "    if cents.shape[0] == 0 or np.all(val_assign == -1):\n",
    "        return np.nan, np.nan\n",
    "    preds = cents[val_assign]\n",
    "    mae  = mean_absolute_error(X_val, preds)\n",
    "    rmse = np.sqrt(mean_squared_error(X_val, preds))\n",
    "    return mae, rmse\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "# 2) KMEANS\n",
    "for k in [3,4,5,6,7,8,10,12]:\n",
    "    km = KMeans(n_clusters=k, n_init=\"auto\", random_state=0)\n",
    "    labels_tr = km.fit_predict(X_train)\n",
    "    im = safe_internal_metrics(X_train, labels_tr)\n",
    "    cents, _ = centroids_from_train(X_train, labels_tr)\n",
    "    val_assign = assign_to_nearest_centroid(X_val, cents)\n",
    "    mae, rmse = external_errors(X_val, cents, val_assign)\n",
    "    results.append({\"algo\":\"kmeans\",\"params\":f\"k={k}\",\"sil\":im[\"sil\"],\"ch\":im[\"ch\"],\"db\":im[\"db\"],\n",
    "                    \"n_clusters\":im[\"n_clusters\"],\"noise\":im[\"frac_noise\"],\"MAE\":mae,\"RMSE\":rmse})\n",
    "\n",
    "# 3) AGGLO\n",
    "for link in [\"ward\",\"average\",\"complete\"]:\n",
    "    for k in [3,4,5,6,7,8,10]:\n",
    "        if link != \"ward\":\n",
    "            ag = AgglomerativeClustering(n_clusters=k, linkage=link)\n",
    "        else:\n",
    "            ag = AgglomerativeClustering(n_clusters=k, linkage=\"ward\")\n",
    "        labels_tr = ag.fit_predict(X_train)\n",
    "        im = safe_internal_metrics(X_train, labels_tr)\n",
    "        cents, _ = centroids_from_train(X_train, labels_tr)\n",
    "        val_assign = assign_to_nearest_centroid(X_val, cents)\n",
    "        mae, rmse = external_errors(X_val, cents, val_assign)\n",
    "        results.append({\"algo\":\"agglo\",\"params\":f\"k={k},link={link}\",\"sil\":im[\"sil\"],\"ch\":im[\"ch\"],\"db\":im[\"db\"],\n",
    "                        \"n_clusters\":im[\"n_clusters\"],\"noise\":im[\"frac_noise\"],\"MAE\":mae,\"RMSE\":rmse})\n",
    "\n",
    "# 4) GMM\n",
    "for k in [3,4,5,6,7,8,10]:\n",
    "    for cov in [\"full\",\"diag\",\"tied\",\"spherical\"]:\n",
    "        gm = GaussianMixture(n_components=k, covariance_type=cov, random_state=0)\n",
    "        gm.fit(X_train)\n",
    "        labels_tr = gm.predict(X_train)\n",
    "        im = safe_internal_metrics(X_train, labels_tr)\n",
    "        cents, _ = centroids_from_train(X_train, labels_tr)\n",
    "        val_assign = assign_to_nearest_centroid(X_val, cents)\n",
    "        mae, rmse = external_errors(X_val, cents, val_assign)\n",
    "        results.append({\"algo\":\"gmm\",\"params\":f\"k={k},cov={cov}\",\"sil\":im[\"sil\"],\"ch\":im[\"ch\"],\"db\":im[\"db\"],\n",
    "                        \"n_clusters\":im[\"n_clusters\"],\"noise\":im[\"frac_noise\"],\"MAE\":mae,\"RMSE\":rmse})\n",
    "\n",
    "# 5) DBSCAN  (tip: scale X first if needed; eps is data-scale sensitive)\n",
    "\n",
    "for eps in [2.0, 3.0, 4.0, 5.0]:     \n",
    "    for ms in [3,5,10]:\n",
    "        db = DBSCAN(eps=eps, min_samples=ms)\n",
    "        labels_tr = db.fit_predict(X_train)\n",
    "        im = safe_internal_metrics(X_train, labels_tr)\n",
    "        cents, _ = centroids_from_train(X_train, labels_tr)\n",
    "        val_assign = assign_to_nearest_centroid(X_val, cents)\n",
    "        mae, rmse = external_errors(X_val, cents, val_assign)\n",
    "        results.append({\"algo\":\"dbscan\",\"params\":f\"eps={eps},min_samples={ms}\",\"sil\":im[\"sil\"],\"ch\":im[\"ch\"],\"db\":im[\"db\"],\n",
    "                        \"n_clusters\":im[\"n_clusters\"],\"noise\":im[\"frac_noise\"],\"MAE\":mae,\"RMSE\":rmse})\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "\n",
    "df_rank = df.copy()\n",
    "\n",
    "\n",
    "df_rank[\"MAE_filled\"] = df_rank[\"MAE\"].fillna(df_rank[\"MAE\"].max() + 1e6)\n",
    "\n",
    "\n",
    "df_rank[\"sil_filled\"] = df_rank[\"sil\"].fillna(-1e6)\n",
    "\n",
    "\n",
    "df_rank[\"db_filled\"] = df_rank[\"db\"].fillna(df_rank[\"db\"].max() + 1e6)\n",
    "\n",
    "# Now rank properly\n",
    "df_rank[\"rank_ext\"] = df_rank[\"MAE_filled\"].rank(method=\"min\")        \n",
    "df_rank[\"rank_sil\"] = (-df_rank[\"sil_filled\"]).rank(method=\"min\")      \n",
    "df_rank[\"rank_db\"]  = df_rank[\"db_filled\"].rank(method=\"min\")        \n",
    "\n",
    "# Sum ranks\n",
    "df_rank[\"rank_sum\"] = df_rank[[\"rank_ext\",\"rank_sil\",\"rank_db\"]].sum(axis=1)\n",
    "\n",
    "# Sort\n",
    "df_sorted = df_rank.sort_values(\"rank_sum\").reset_index(drop=True)\n",
    "\n",
    "df_sorted.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df_eval = pd.read_csv(\"evaluation_dataset_exercise_5_clustering_highway_traffic.csv\",sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation dataset vectorized: (80, 288)\n"
     ]
    }
   ],
   "source": [
    "def vectorize_dataset(df, date_col=\"Date\", interval_col=\"Interval_5\", value_col=\"flow\", n_intervals=288):\n",
    "    df_sorted = df.sort_values([date_col, interval_col])\n",
    "    out = (df_sorted.pivot(index=date_col, columns=interval_col, values=value_col)\n",
    "                    .reindex(columns=range(n_intervals))\n",
    "                    .sort_index())\n",
    "    X = out.to_numpy()\n",
    "    days = out.index.to_numpy()\n",
    "    return X, days\n",
    "\n",
    "# Apply to evaluation dataset\n",
    "vectorized_day_dataset_eval, eval_days = vectorize_dataset(\n",
    "    data_df_eval, date_col=\"Date\", interval_col=\"Interval_5\", value_col=\"flow\"\n",
    ")\n",
    "\n",
    "print(\"Evaluation dataset vectorized:\", vectorized_day_dataset_eval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final evaluation on evaluation dataset:\n",
      "MAE: 21.144787423826216\n",
      "RMSE: 30.947059458287207\n"
     ]
    }
   ],
   "source": [
    "def centroids_from_labels(X, labels):\n",
    "    cents = [X[labels==c].mean(axis=0) for c in sorted(set(labels) - {-1})]\n",
    "    return np.vstack(cents) if cents else np.empty((0, X.shape[1]))\n",
    "\n",
    "def assign_to_nearest_centroid(X_new, C):\n",
    "    if C.shape[0] == 0:\n",
    "        return np.full(X_new.shape[0], -1)\n",
    "    x2 = np.sum(X_new**2, axis=1, keepdims=True)\n",
    "    c2 = np.sum(C**2, axis=1, keepdims=True).T\n",
    "    return np.argmin(x2 + c2 - 2*(X_new @ C.T), axis=1)\n",
    "\n",
    "def eval_on_dataset(X_train_like, X_eval_like, model):\n",
    "    labels = model.fit_predict(X_train_like) if hasattr(model, \"fit_predict\") else model.predict(X_train_like)\n",
    "    C = centroids_from_labels(X_train_like, labels)\n",
    "    idx = assign_to_nearest_centroid(X_eval_like, C)\n",
    "    if C.shape[0] == 0 or np.all(idx == -1):\n",
    "        return np.nan, np.nan\n",
    "    preds = C[idx]\n",
    "    mae = mean_absolute_error(X_eval_like, preds)\n",
    "    rmse = np.sqrt(mean_squared_error(X_eval_like, preds))\n",
    "    return mae, rmse\n",
    "\n",
    "# 3. Final Model\n",
    "\n",
    "best_model = AgglomerativeClustering(n_clusters=7, linkage=\"average\")\n",
    "\n",
    "\n",
    "# 4. Run final evaluation\n",
    "\n",
    "\n",
    "X_full, _ = vectorize_dataset(data_df)  \n",
    "X_full = X_full[~np.any(np.isnan(X_full), axis=1)]\n",
    "X_eval = vectorized_day_dataset_eval[~np.any(np.isnan(vectorized_day_dataset_eval), axis=1)]\n",
    "\n",
    "mae, rmse = eval_on_dataset(X_full, X_eval, best_model)\n",
    "\n",
    "print(\"Final evaluation on evaluation dataset:\")\n",
    "print(\"MAE:\", mae)\n",
    "print(\"RMSE:\", rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
